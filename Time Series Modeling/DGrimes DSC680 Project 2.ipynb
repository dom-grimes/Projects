{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0dd365",
   "metadata": {},
   "source": [
    "Author: Dominique Grimes\n",
    "\n",
    "Date: July 21, 2024\n",
    "\n",
    "Topic: Sales prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import association_metrics as am\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import pmdarima as pm\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "# plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options to see max columns and rows\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Supress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into df\n",
    "sales = pd.read_csv('Amazon Sale Report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed41ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verify data loaded \n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18677b16",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fe10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headers that have spaces\n",
    "sales = sales.rename(columns={\"Order ID\": \"Order_ID\", \"Sales Channel \": \"Sales_Channel\", \"Courier Status\": \"Courier_Status\", \"Unnamed: 22\": \"Unnamed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify new column headers\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a68d2",
   "metadata": {},
   "source": [
    "## Observe and manage null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting NaN values in all columns\n",
    "nan_count = sales.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bda895",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90bc1bb",
   "metadata": {},
   "source": [
    "Initial thoughts\n",
    "- Courier_Status may be correlated with Status. If so, drop.\n",
    "- Amount needs to be observed for why the values are null. May be dependent on another feature. If not, replace price with average price for similar style clothing.\n",
    "- Ship postal code may be due to cancellations. If not, impute the mode.\n",
    "- I simplified this column into a binary feature to observe if a promotion was or was not applied. \n",
    "- fulfilled-by can be dropped since this item is dependent on Fulfilment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca1249",
   "metadata": {},
   "source": [
    "## Observe value counts for each categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d33d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Fulfilment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cf33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Sales_Channel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['ship-service-level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Courier_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63085648",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead59052",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Size'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557465b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Qty'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe45e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['currency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40afc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['ship-city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2297441",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['ship-state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['ship-state'] = sales['ship-state'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['ship-state'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['ship-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a173c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['promotion-ids'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45072b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['fulfilled-by'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Unnamed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['B2B'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7409e",
   "metadata": {},
   "source": [
    "## Drop columns with little to no variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4294aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Order_ID is unique. \n",
    "sales['Order_ID'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459636a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Order_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "sales.drop(['Order_ID','index','ship-country', 'Unnamed','currency','ship-city','ship-state','SKU'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify df shape\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad2f5b",
   "metadata": {},
   "source": [
    "### promotion-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bafb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change promotion-ids to binary\n",
    "sales['promotion-ids'] = sales['promotion-ids'].where(~sales['promotion-ids'].notna(), 1)\n",
    "sales['promotion-ids'] = sales['promotion-ids'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece130ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headee for promotion-ids to promotion\n",
    "sales = sales.rename(columns={\"promotion-ids\": \"promotion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa76554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify column header change\n",
    "sales.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4edc0",
   "metadata": {},
   "source": [
    "### ship-postal-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de023833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View number of unique postal codes\n",
    "sales['ship-postal-code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting rows where postal code is na \n",
    "null_pc = sales[sales['ship-postal-code'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View null postal code df\n",
    "null_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054b892",
   "metadata": {},
   "source": [
    "I did not observe any obvious relationships between the null postal codes and the rest of the features. I will replace the 33 null postal codes with the mode zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mode of the postal code feature\n",
    "sales['ship-postal-code'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a78712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute na values for ship-postal-code with mode 201301.0\n",
    "sales['ship-postal-code']=sales['ship-postal-code'].fillna(201301.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391056c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting NaN values in all columns\n",
    "nan_count = sales.isna().sum()\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584659d",
   "metadata": {},
   "source": [
    "### Courier_Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9ab88",
   "metadata": {},
   "source": [
    "Observe when there are zero quantities purchased how much the sales are for 0 quantity.\n",
    "Look at relationship between qty and courrier status.\n",
    "Assume if NAN then 0 qty.This is due to being cancelled.\n",
    "Look at relationship between status and courier status\n",
    "courier status: Observe shipped, unshipped, cancelled behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review value counts for Courier_Satus again. Note: 6,872 null values\n",
    "sales['Courier_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review value counts for Qty again focusing sales with zero Qty\n",
    "sales['Qty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2aa2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the sales df with values Qty = 0\n",
    "filtered_sales = sales[sales['Qty'] == 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View value counts of the filtered data frame for all courier statuses when Qty = 0\n",
    "filtered_sales['Courier_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NaN values of filtered df and observe number of null values for Courier_Status\n",
    "nan_count1 = filtered_sales.isna().sum()\n",
    "nan_count1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c8b3e",
   "metadata": {},
   "source": [
    "Total values of filtered dataframe when Qty = 0 is 6872 null Carrier Status + 5935 Cancelled Status = 12807 of total Qty 0 in the unfiltered dataframe. I'm chosing to replace null Courier_Status with Cancelled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f10f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute na values for Courier_Status with Cancelled\n",
    "sales['Courier_Status']=sales['Courier_Status'].fillna('Cancelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038beebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify replaced na values\n",
    "sales['Courier_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dac94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting NaN values in all columns\n",
    "nan_count2 = sales.isna().sum()\n",
    "nan_count2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52198eaa",
   "metadata": {},
   "source": [
    "### Fulfilled-by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulfilledna = sales[sales['fulfilled-by'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulfilledna['Fulfilment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulfilledna = sales[sales['fulfilled-by'] == 'Easy Ship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulfilledna['Fulfilment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99242a68",
   "metadata": {},
   "source": [
    "Fulfilment is binary with Amazon or Merchant. This is directly related to fulfilled-by. If not fulfilled by Amazon, then the merchant is Easy Street. Since this is the case, I will drop fulfilled-by and change Fulfilment to a binary feature in the Feature Engineering section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf3401",
   "metadata": {},
   "source": [
    "### Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30627ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting rows where Amount is na \n",
    "null_Amount = sales[sales['Amount'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View filtered data\n",
    "null_Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the row count of the filtered data\n",
    "null_Amount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88127bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the number of each category for Courier_Status\n",
    "null_Amount['Courier_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5a687",
   "metadata": {},
   "source": [
    "There are no Shipped values when Amount is null. Most are cancelled with a vew unshipped. Observe if the qty is 0 for these and what the price Amount is for cancelled items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f65d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Counts of each quantity when Amounts are null\n",
    "null_Amount['Qty'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64daa08",
   "metadata": {},
   "source": [
    "The majority of the null Amounts have a qty of zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92566098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with Amount and Category\n",
    "Cat_Amt = sales[['Category', 'Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea9de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View new df\n",
    "Cat_Amt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036dd8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_Amount = sales.groupby('Category')['Amount'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3d551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the average sales per category\n",
    "Cat_ave_Amount = average_Amount.round(2)\n",
    "Cat_ave_Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1249c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values with the average value of each category\n",
    "sales['Amount'] = sales.groupby('Category')['Amount'].transform(lambda x: x.fillna(x.mean()))\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065472b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the null valies for Amount\n",
    "sales['Amount'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90915f0",
   "metadata": {},
   "source": [
    "None of the Amounts are zero when the Courier_Status is cancelled. I will investigate why there are zero amounts that are not cancelled in the Analysis of Continuous variables section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e482999",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9112dfa",
   "metadata": {},
   "source": [
    "### Create binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the get_dummies method. The first parameter mentions the the name of the data frame to store the \n",
    "# new data frame in the second parameter is the list of columns which if not mentioned returns the dummies for \n",
    "# binomial columns \n",
    "\n",
    "sales_dummies = pd.get_dummies(sales, columns = ['Fulfilment', 'B2B', 'ship-service-level','Sales_Channel']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 2nd dummy column of binomial features\n",
    "sales_dummies.drop(['Fulfilment_Merchant','B2B_False', 'ship-service-level_Standard','Sales_Channel_Non-Amazon', 'fulfilled-by'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8f79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View df to verify the feature was dropped\n",
    "sales_dummies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1c966",
   "metadata": {},
   "source": [
    "#### Split Status Column and create Returned binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8f558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View value counts for the items in the Status column\n",
    "sales['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c399147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new features that split the column values on the \"-\"\n",
    "sales_dummies[['Status2', 'Status3']] = sales_dummies['Status'].str.split(' - ', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Status3 to Returned\n",
    "sales_dummies.rename(columns={\"Status3\": \"Returned\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55457363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Status 3 into binary feature and update values to 0 or 1 accordingly\n",
    "sales_dummies['Returned'].replace({'Delivered to Buyer':0, 'Returned to Seller':1, 'Picked Up':0,'Waiting for Pick Up':0, 'Returning to Seller':1, 'Out for Delivery':0, 'Rejected by Buyer':1, 'Lost in Transit':0, 'Damaged':1, 'None':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View value counts for new Returned feature\n",
    "sales_dummies['Returned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null Returned values with 0\n",
    "sales_dummies['Returned'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe value counts after null vaues replaced\n",
    "sales_dummies['Returned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify there are no remaining null returned values\n",
    "sales_dummies['Returned'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc825007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dtype of Returned to int\n",
    "sales_dummies['Returned'] = sales_dummies['Returned'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce354f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the dtype was updated\n",
    "sales_dummies['Returned'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858634d",
   "metadata": {},
   "source": [
    "### Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to datetime\n",
    "sales_dummies['Date'] = pd.to_datetime(sales_dummies['Date'],format='%m-%d-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the feature into mont, day, year, dayofweek, and week features\n",
    "sales_dummies['month'] = sales_dummies['Date'].dt.month\n",
    "sales_dummies['day'] = sales_dummies['Date'].dt.day\n",
    "sales_dummies['year'] = sales_dummies['Date'].dt.year\n",
    "sales_dummies['dayofweek'] = sales_dummies['Date'].dt.dayofweek\n",
    "sales_dummies['week'] = sales_dummies['Date'].dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebe48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the new features were created\n",
    "sales_dummies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the values for year\n",
    "sales_dummies['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac93f20",
   "metadata": {},
   "source": [
    "I will drop year since no variation as well as Date since the infomation has been spit into feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date and year features\n",
    "sales_dummies.drop('year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dummies['Category'] = sales_dummies['Category'].astype('category')\n",
    "sales_dummies['Size'] = sales_dummies['Size'].astype('category')\n",
    "sales_dummies['Qty'] = sales_dummies['Qty'].astype('int')\n",
    "sales_dummies['ship-postal-code'] = sales_dummies['ship-postal-code'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef20e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dummies['Courier_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dummies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dummies['Category'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1bb79",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d96ba",
   "metadata": {},
   "source": [
    "## Continuous feature Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557bd29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales['Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e78b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Observe distribution of Amount through histogram\n",
    "\n",
    "# Plotting a basic histogram\n",
    "plt.hist(sales['Amount'], bins=100, color='skyblue', edgecolor='black')\n",
    " \n",
    "# Adding labels and title\n",
    "plt.xlabel('Sales Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Amazon Sales Amounts (INR)')\n",
    " \n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21f33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Observe distribution of Amount through boxplot\n",
    "fig = px.box(sales, y=\"Amount\", title='Boxplot of Amount')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2c5ab",
   "metadata": {},
   "source": [
    "Even though there are some outliers, they seem like relevant values that will impact sales. I am chosing not to remove them at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b04e1",
   "metadata": {},
   "source": [
    "Explore if cancelled items have zero amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9120809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data frame for Courier_Status of cancelled\n",
    "can = sales[sales['Courier_Status']=='Cancelled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1efc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Oberve the Amounts for cancelled items that are zero. \n",
    "len(can[can['Amount'] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c2c2a",
   "metadata": {},
   "source": [
    "There are no cancelled items when the amount is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfeec16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Observe the lenth of items in the original df where Amount is zero\n",
    "len(sales[sales['Amount'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df that filters the data with zero amounts\n",
    "zeroAMT = sales[sales['Amount'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b66df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View df\n",
    "zeroAMT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927df68",
   "metadata": {},
   "source": [
    "There is nothing obvious causing the to zero amounts like cancelled items or zero qty. This seems to be an error. I will replace zero and null Amounts with the average prices per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e410e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero amounts with the mean\n",
    "sales['Amount'] = sales.groupby('Category')['Amount'].transform(lambda x: x.replace(0,x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the count of zero Amounts after imputation\n",
    "len(sales[sales['Amount'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cea1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verify the mean Amounts per category after imputation\n",
    "check = sales.groupby('Category')['Amount'].mean().round(2)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f487e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare to the original mean Amounts per category \n",
    "Cat_ave_Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69337ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe distribution of Amount through histogram with encoded data\n",
    "\n",
    "# Plotting a basic histogram\n",
    "plt.hist(sales['Amount'], bins=100, color='skyblue', edgecolor='black')\n",
    " \n",
    "# Adding labels and title\n",
    "plt.xlabel('Sales Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Amounts after Zero Imputation')\n",
    " \n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98aebf4",
   "metadata": {},
   "source": [
    "The new mean amounts are slightly higher which is to be expected since the amounts are skewed by the inaccurate 0 Amounts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76edff",
   "metadata": {},
   "source": [
    "## Time related distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ed1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe that sorted by date in ascending order\n",
    "sorted_time = sales_dummies.sort_values(by = ['Date'], ascending = True)\n",
    "sorted_time.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with total sales per day\n",
    "date_df = sorted_time.groupby(sorted_time['Date'])['Amount'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a728a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the df\n",
    "date_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadd3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the time series sales data\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(date_df['Date'],date_df['Amount'], color='skyblue')\n",
    "\n",
    "# Name the x axis \n",
    "plt.xlabel('Date') \n",
    "# Name the y axis \n",
    "plt.ylabel('Total Retail Sales per day') \n",
    "  \n",
    "# Add graph title\n",
    "plt.title('Total Retail Sales per Day from March 31, 2022 to June 29, 2022') \n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb2bd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# View the value counts of the month feature\n",
    "sales_dummies['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the distribution of day feature through value counts\n",
    "# Create a df that provides the value counts for each day\n",
    "day=sales_dummies['day'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observe distribution of Date through histogram\n",
    "\n",
    "# Plotting a basic histogram\n",
    "plt.hist(sales_dummies['day'], bins=30, color='skyblue', edgecolor='black')\n",
    " \n",
    "# Adding labels and title\n",
    "plt.xlabel('Date of Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Amazon Sales Date')\n",
    " \n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00550347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe distribution of day of week counts through value counts\n",
    "sales_dummies['dayofweek'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b96956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe distribution of day of week through histogram\n",
    "\n",
    "# Plotting a basic histogram\n",
    "plt.hist(sales_dummies['dayofweek'], bins=7, color='skyblue', edgecolor='black')\n",
    " \n",
    "# Adding labels and title\n",
    "plt.xlabel('Date of Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Amazon Sales Day of Week')\n",
    " \n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe distribution of week of the year counts through value counts\n",
    "sales_dummies['week'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observe distribution of week of the year through histogram\n",
    "\n",
    "# Plotting a basic histogram\n",
    "plt.hist(sales_dummies['week'], bins=14, color='skyblue', edgecolor='black')\n",
    " \n",
    "# Adding labels and title\n",
    "plt.xlabel('Date of Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Amazon Sales Week of Year')\n",
    " \n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f64e8e",
   "metadata": {},
   "source": [
    "Week of the year distribution looks bimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee41e06",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d32c66",
   "metadata": {},
   "source": [
    "#### Observe if there are correlations between Status2 and Courier_Status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46408a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare status2 and Courier_Status\n",
    "\n",
    "# Status2 value counts\n",
    "sales_dummies['Status2'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400285f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Courier_Status value counts\n",
    "sales_dummies['Courier_Status'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert str columns to Category columns\n",
    "df = sales_dummies[{'Status2','Courier_Status'}]\n",
    "df = df.apply(lambda x: x.astype(\"category\") if x.dtype == \"O\" else x)\n",
    "\n",
    "# Initialize a CamresV object using pandas.DataFrame\n",
    "cramersv = am.CramersV(df) \n",
    "\n",
    "# return a pairwise matrix filled with Cramer's V, where columns and index are \n",
    "# the categorical variables of the passed pandas.DataFrame\n",
    "cramersv.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b63d4",
   "metadata": {},
   "source": [
    "There is a strong correlation between the two features. I will choose to drop Status & Status2 feature and update Courier_Status to categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb32669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop correlated features\n",
    "sales_dummies.drop(['Status','Status2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d49e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify features were dropped\n",
    "sales_dummies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to Courier_Status data type to category\n",
    "sales_dummies['Courier_Status'] = sales_dummies['Courier_Status'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d60978",
   "metadata": {},
   "source": [
    "#### Correlation of Style and ASIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aae652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert you str columns to Category columns\n",
    "df1 = sales_dummies[{'Style','ASIN'}]\n",
    "df1 = df1.apply(lambda x: x.astype(\"category\") if x.dtype == \"O\" else x)\n",
    "\n",
    "# Initialize a CamresV object\n",
    "cramersv1 = am.CramersV(df1) \n",
    "\n",
    "# matrix filled with Cramer's V, where columns and index are \n",
    "# the categorical variables of the df\n",
    "cramersv1.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78c5f7",
   "metadata": {},
   "source": [
    "Highly correlated. I will drop ASIN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea5da6",
   "metadata": {},
   "source": [
    "#### Correlation of Style and Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a988baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert you str columns to Category columns\n",
    "df2 = sales_dummies[{'Style','Category'}]\n",
    "df2 = df2.apply(\n",
    "        lambda x: x.astype(\"category\") if x.dtype == \"O\" else x)\n",
    "\n",
    "# Initialize a CamresV object using you pandas.DataFrame\n",
    "cramersv2 = am.CramersV(df2) \n",
    "# will return a pairwise matrix filled with Cramer's V, where columns and index are \n",
    "# the categorical variables of the passed pandas.DataFrame\n",
    "cramersv2.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc3665",
   "metadata": {},
   "source": [
    "Highly correlated. I will drop Style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop correlated features\n",
    "sales_dummies.drop(['ASIN'], axis=1, inplace=True)\n",
    "sales_dummies.drop(['Style'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123ee68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verify dropped features\n",
    "sales_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32585819",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154d30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Size' column\n",
    "sales_dummies['Size_encoded'] = label_encoder.fit_transform(sales['Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder2 = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Size' column\n",
    "sales_dummies['Category_encoded'] = label_encoder2.fit_transform(sales['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the new encoded feature\n",
    "sales_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the Size value counts\n",
    "sales_dummies['Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f50d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the encoded value counts\n",
    "sales_dummies['Size_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6248d5d",
   "metadata": {},
   "source": [
    "* 0, 3XL\n",
    "* 1, 4XL\n",
    "* 2, 5XL\n",
    "* 3, 6XL\n",
    "* 4, Free\n",
    "* 5, L\n",
    "* 6, M\n",
    "* 7, S\n",
    "* 8, XL\n",
    "* 9, XS\n",
    "* 10, XXL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for Courier_Status\n",
    "encoded = pd.get_dummies(sales_dummies, columns=['Courier_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87607fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original features\n",
    "encoded.drop(['Size', 'Category'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the df in ascending date order\n",
    "encoded = encoded.sort_values(by = ['Date'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d9ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the sorted df\n",
    "encoded.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70edaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded['Amount']=encoded['Amount'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e546896",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using decomposition to observe trends and seasonality in the data\n",
    "\n",
    "result = seasonal_decompose(date_df['Amount'], period=7)\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c1f73",
   "metadata": {},
   "source": [
    "There is a slight downward trend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4818a",
   "metadata": {},
   "source": [
    "## Dicky-Fuller test\n",
    "\n",
    "Check to see if the data is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(date_df['Amount'].values)\n",
    "print('ADF test statistic:', adf)\n",
    "print('ADF p-values:', pval)\n",
    "print('ADF number of lags used:', usedlag)\n",
    "print('ADF number of observations:', nobs)\n",
    "print('ADF critical values:', crit_vals)\n",
    "print('ADF best information criterion:', icbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522a218",
   "metadata": {},
   "source": [
    "The p-value is less than .05, therefore I'm determining it's stationary and differencing is not needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1645913",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd382e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(date_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "train_df = date_df[date_df['Date'] <= '2022-06-14']\n",
    "test_df = date_df[date_df['Date'] > '2022-06-14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training dataframe to observe dataframes were split correctly\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the test dataframe to observe dataframes were split correctly\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding date related features to the train dataset for modeling\n",
    "train_df['dayofweek'] = train_df['Date'].dt.dayofweek\n",
    "train_df['month'] = train_df['Date'].dt.month\n",
    "train_df['dayofyear'] = train_df['Date'].dt.dayofyear\n",
    "train_df['dayofmonth'] = train_df['Date'].dt.day\n",
    "train_df['weekofyear'] = train_df['Date'].dt.weekofyear\n",
    "\n",
    "# Adding date related features to the train dataset for modeling\n",
    "test_df['dayofweek'] = test_df['Date'].dt.dayofweek\n",
    "test_df['month'] = test_df['Date'].dt.month\n",
    "test_df['dayofyear'] = test_df['Date'].dt.dayofyear\n",
    "test_df['dayofmonth'] = test_df['Date'].dt.day\n",
    "test_df['weekofyear'] = test_df['Date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd781ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4775d",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d71ad",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ARIMA model with automated optimization of hyperparameters \n",
    "model = pm.auto_arima(train_df['Amount'], seasonal=False, stepwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8932fce6",
   "metadata": {},
   "source": [
    "### Predict Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict retail sales based on the test dataset\n",
    "preds = model.predict(test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4abb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View predicted values\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec620b",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f954d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(preds,index = test_df.index,columns=['preds'])\n",
    "\n",
    "pd.concat([date_df['Amount'],forecast_df],axis=1).plot(color = ['skyblue','red'], \n",
    "                                                                title = 'Daily Amazon Sales with Auto ARIMA Predicted Sales')\n",
    "# Name the x axis \n",
    "plt.xlabel('Index of Day') \n",
    "# Name the y axis \n",
    "plt.ylabel('Total Retail Sales per Day') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ecac3",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean squared error of the test sales and predicted sales\n",
    "mse = mean_squared_error(test_df['Amount'], preds)\n",
    "\n",
    "# Calculate the square root of the mean quared error \n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# View root mean squared error\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c31709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calulate the weighted mean average percentage error\n",
    "def wmape(y_true, y_pred):\n",
    "        return np.sum(np.abs(y_true - y_pred))/ np.sum(np.abs(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e948a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the wmape as a second evaluation metric\n",
    "wmape(test_df['Amount'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c565c8",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716832ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt a Random Forest Regression model\n",
    "\n",
    "# Set train variable\n",
    "X = train_df[['dayofweek', 'month', 'dayofyear',\n",
    "       'dayofmonth', 'weekofyear']]\n",
    "\n",
    "# Fit the model\n",
    "my_rf = RandomForestRegressor()\n",
    "my_rf.fit(X, train_df['Amount'])\n",
    "\n",
    "# Precit based on test data\n",
    "X_test = test_df[['dayofweek', 'month', 'dayofyear',\n",
    "       'dayofmonth', 'weekofyear']]\n",
    "pred_test = my_rf.predict(X_test)\n",
    "\n",
    "# View predicted values\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View actual values\n",
    "test_df['Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mse and rmse\n",
    "rfr_mse = mean_squared_error(test_df['Amount'], pred_test)\n",
    "rfr_rmse = math.sqrt(rfr_mse)\n",
    "\n",
    "# View rmse\n",
    "rfr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View wmape\n",
    "wmape(test_df['Amount'], pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61aedb",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446adbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the Linear Regression model\n",
    "my_lr = LinearRegression()\n",
    "my_lr.fit(X, train_df['Amount'].values)\n",
    "\n",
    "# Predict on the test period\n",
    "predsLR = my_lr.predict(X_test)\n",
    "\n",
    "# Calculate mse and rmse\n",
    "LR_mse = mean_squared_error(test_df['Amount'], predsLR)\n",
    "LR_rmse = math.sqrt(LR_mse)\n",
    "\n",
    "# View rmse\n",
    "LR_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab77b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View wmape\n",
    "wmape(test_df['Amount'], predsLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702cf7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast on the test data\n",
    "test_df['Amount_Preds'] = predsLR\n",
    "\n",
    "# Combine actual and predicted values in one dataframe\n",
    "Amount_all2 = pd.concat([test_df, train_df], sort=False)\n",
    "\n",
    "# Plot the acutal vs predicted values\n",
    "_ = Amount_all2[['Amount','Amount_Preds']].plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bdc67",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2264898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date column as the index\n",
    "date_index = date_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7202def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date to datetime\n",
    "pd.to_datetime(date_index.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8aa652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sales over timeperiod\n",
    "date_index['Amount'].plot(style='.', \n",
    "                          figsize=(15,5), \n",
    "                          title = \"Amazon Sales per Day from March 31, 2022 to June 29, 2022\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create time related features\n",
    "\n",
    "def create_features(df, label=None):\n",
    "    \"\"\"\n",
    "    Creates time series features from datetime index\n",
    "    \"\"\"\n",
    "    df['date'] = df.index\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.weekofyear\n",
    "    \n",
    "    X = df[['hour','dayofweek','quarter','month','year',\n",
    "           'dayofyear','dayofmonth','weekofyear']]\n",
    "    if label:\n",
    "        y = df[label]\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbba146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets based on 6/14/22 date\n",
    "train = date_index.loc[date_index.index < '2022-06-14']\n",
    "test = date_index.loc[date_index.index >= '2022-06-14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b480c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test, Split\n",
    "X_train, y_train = create_features(train, label='Amount')\n",
    "X_test, y_test = create_features(test, label='Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea81578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "reg = xgb.XGBRegressor(n_estimators=1000, early_stopping_rounds=50)\n",
    "reg.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "        verbose=False) # Change verbose to True if you want to see it train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe feature importance\n",
    "_ = plot_importance(reg, height=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b126b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast on the test data\n",
    "test['Amount_Prediction'] = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine actual and predicted values in one dataframe\n",
    "Amount_all = pd.concat([test, train], sort=False)\n",
    "\n",
    "# Plot the acutal vs predicted values\n",
    "_ = Amount_all[['Amount','Amount_Prediction']].plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with mse\n",
    "XGBmse = mean_squared_error(y_true=test['Amount'],\n",
    "                   y_pred=test['Amount_Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba83dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rmse\n",
    "math.sqrt(XGBmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with wmape\n",
    "wmape(test['Amount'], test['Amount_Prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
